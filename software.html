<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="webthemez">
    <title>ACE Lab</title>
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/font-awesome.min.css" rel="stylesheet">
    <link href="css/animate.min.css" rel="stylesheet"> 
    <link href="css/prettyPhoto.css" rel="stylesheet">
    <link href="css/styles.css" rel="stylesheet"> 
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons/css/academicons.min.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous"> 
    <link rel="shortcut icon" href="images/ico/favicon.ico"> 
    <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
</head> 

<body id="home">

    <header id="header">
        <nav id="main-nav" class="navbar navbar-default navbar-fixed-top" role="banner">
            <div class="container text-center">
                <!-- Logo 居中 -->
                <div class="navbar-header" style="margin: 0 auto;">
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="index.html">
                        <img src="images/logo_alt_2.png" alt="logo" style="display: block; margin: 0 auto;">
                    </a>
                </div>
    
                <!-- 导航菜单居中 -->
                <div class="collapse navbar-collapse" style="justify-content: center;">
                    <ul class="nav navbar-nav" style="display: inline-block; float: none;">
                        <li class="scroll"><a href="index.html">About</a></li>
                        <li class="scroll"><a href="team.html">Team</a></li>
                        <li class="dropdown">
                            <a href="project.html" class="dropdown-toggle" data-toggle="dropdown">Research <b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="grants.html">Grants</a></li>
                                <li><a href="project.html">Research</a></li>
                            </ul>
                        </li>
                        <!-- <li class="scroll"><a href="project.html">Research</a></li> -->
                        <li class="scroll"><a href="publications.html">Publications</a></li>
                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">Downloads <b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="software.html">Software</a></li>
                                <li><a href="curriculum.html">Innovative Curriculum</a></li>
                                <li><a href="datasets.html">Public Datasets</a></li>
                            </ul>
                        </li>
                        <li class="scroll"><a href="contactUs.html">Contact Us</a></li>
                    </ul>
                </div>
            </div>
        </nav>
    </header>



 <section id="about">
    
        <div class="container">
            <div class="section-header">
                <h4 class="section-title wow fadeInDown">Packages and Analytical Tools</h4>
            </div>
        </div>

        <div class="container">
            <div class="row">
                <!-- img-responsive -->
                <div class="col-md-4 wow fadeInLeft">
                    <!-- img-responsive -->
                  <a href='https://huggingface.co/uf-aice-lab/Llama-2-QLoRA' style='color:#2596be' target="_blank"><img class="img-square" src="images/LLAMA2.png" style="text-align:center" alt="">
                  <h3>Math-Llama-2-QLoRA</h3></a>
                </div>

                <div class="col-md-8 wow fadeInRight">
                    <!--<h3 class="column-title">Our Company</h3>-->
                    <p style="margin-top: 5%;"><span style='text-decoration:underline'><a href='https://huggingface.co/uf-aice-lab/Llama-2-QLoRA' style='color:#2596be' target="_blank">Math-Llama-2-QLoRA</a></span>: is a pretrained large language model based on LLaMA-2 with 8 Nvidia A100-80G GPUs using 3,000,000 groups of conversations in the context of mathematics by students and facilitators on Algebra Nation (https://www.mathnation.com/). Llama-2-Qlora consists of 32 layers and over 7 billion parameters, consuming up to 13.5 gigabytes of disk space. Researchers can experiment with and finetune the model to help construct math conversational AI that can effectively respond generation in a mathematical context.  </p>

                </div>
            </div>
        </div>

        <br>
        <hr>
        <div class="container">
            <div class="row">
                <!-- img-responsive -->
                <div class="col-md-4 wow fadeInLeft">
                    <!-- img-responsive -->
                  <a href='https://huggingface.co/uf-aice-lab/Llama_Lora' style='color:#2596be' target="_blank"><img class="img-square" src="images/LLAMA1.jpg" style="text-align:center" alt="">
                  <h3>Math-Llama_Lora</h3></a>
                </div>

                <div class="col-md-8 wow fadeInRight">
                    <!--<h3 class="column-title">Our Company</h3>-->
                    <p style="margin-top: 5%;"><span style='text-decoration:underline'><a href='https://huggingface.co/uf-aice-lab/Llama_Lora' style='color:#2596be' target="_blank">Math-Llama_Lora</a></span>: is a pretrained LLM extending from LLaMA with 8 Nvidia A100-80G GPUs using 3,000,000 groups of conversations in the context of mathematics by students and facilitators on Algebra Nation (https://www.mathnation.com/). Llama-mt-lora consists of 32 layers and over 7 billion parameters, consuming up to 13.5 gigabytes of disk space. Researchers can experiment with and finetune the model to help construct math conversational AI that can effectively respond generation in a mathematical context.  </p>

                </div>
            </div>
        </div>

        <br>
        <hr>
        <div class="container">
            <div class="row">
                <!-- img-responsive -->
                <div class="col-md-4 wow fadeInLeft">
                    <!-- img-responsive -->
                  <a href='https://huggingface.co/uf-aice-lab/Math-GPT-J' style='color:#2596be' target="_blank"><img class="img-square" src="images/GPT_j.jpeg" style="text-align:center" alt="">
                  <h3>Math-GPT-J</h3></a>
                </div>

                <div class="col-md-8 wow fadeInRight">
                    <!--<h3 class="column-title">Our Company</h3>-->
                    <p style="margin-top: 5%;"><span style='text-decoration:underline'><a href='https://huggingface.co/uf-aice-lab/Math-GPT-J' style='color:#2596be' target="_blank">Math-GPT-J</a></span>: is a pretrained GPT-J-6B model (GPT-J 6B is a large language model trained using Ben Wang's Mesh Transformer JAX)  trained with 8 Nvidia A-100 GPUs using 3,000,000 math discussion posts by students and facilitators on Algebra Nation (https://www.mathnation.com/). Math-GPT-J uses Rotary Position Embeddings, which has been found to be a superior method of injecting positional information into transformers. It has 28 layers, and 6 billion parameters and its published model weights take up to 24 gigabytes of disk space. It can potentially provide a good base performance on NLP related tasks (e.g., text classification, semantic search, Q&A) in similar math learning environments.  </p>

                </div>
            </div>
        </div>
        
        <br>
        <hr>
        <div class="container">
            <div class="row">
                <!-- img-responsive -->
                <div class="col-md-4 wow fadeInLeft">
                    <!-- img-responsive -->
                  <a href='https://github.com/uf-aice-lab/rag-knowledge-graph' style='color:#2596be' target="_blank"><img class="img-square" src="images/knowledge_graph.png" style="text-align:center;width: 220px" alt="">
                  <h3>Knowledge-Graph for RAG</h3></a>
                </div>

                <div class="col-md-8 wow fadeInRight">
                    <!--<h3 class="column-title">Our Company</h3>-->
                    <p style="margin-top: 5%;"><span style='text-decoration:underline'><a href='https://github.com/uf-aice-lab/rag-knowledge-graph' style='color:#2596be' target="_blank">Knowledge-Graph for RAG</a></span>: This repository contains code for building retrieval-augmented generation (RAG) systems using LLMs such as GPT-4 and Llama 3. The RAG techniques employed include vector-based context retrieval, tree-based, and graph-based (our in-house approach) methods. Additionally, this repository includes code for a semantic classifier utilizing various techniques. It also contains a web application using the knowledge-graph based context retrieval technique.
                    </p>

                </div>
            </div>
        </div>
        <!--uf-aice-lab/Llama-2-QLoRA-->
        <br>
        <hr>

        <br>
        <hr>
        <div class="container">
            <div class="row">
                <!-- img-responsive -->
                <div class="col-md-4 wow fadeInLeft">
                    <!-- img-responsive -->
                  <a href='https://huggingface.co/DukeNLP/Prob-Gen-8B' style='color:#2596be' target="_blank"><img class="img-square" src="images/prob-gen.jpg" style="text-align:center; width: 220px" alt="">
                  <h3>Prob-Gen-Llama</h3></a>
                </div>

                <div class="col-md-8 wow fadeInRight">
                    <!--<h3 class="column-title">Our Company</h3>-->
                    <p style="margin-top: 5%;"><span style='text-decoration:underline'><a href='https://huggingface.co/DukeNLP/Prob-Gen-8B' style='color:#2596be' target="_blank">Prob-Gen-Llama</a></span>: has two versions of LLMs, a 8B and a 70B Llama-3, fine-tuned using 4-bit QLORA. In collaboration with the Duke NLP lab, we utilized 3,644 GPT-4-generated grade school math word problems vetted by three content experts with PhD degrees in mathematics education. It generates math word problems with contrasting cases, a powerful learning sciences theory evidenced to be effective for math learning, within specified contexts.  
                    </p>
                </div>
            </div>
        </div>
        <!--uf-aice-lab/Llama-2-QLoRA-->
        <br>
        <hr>

        <div class="container">
            <div class="row">
                <!-- img-responsive -->
                <div class="col-md-4 wow fadeInLeft">
                    <!-- img-responsive -->
                  <a href='https://huggingface.co/uf-aice-lab/math-roberta' style='color:#2596be' target="_blank">
                  <img class="img-square" src="images/roberta.png" alt="">
                  <h3 >MathRoBERTa</h3>
                  </a>
                </div>

                <div class="col-md-8 wow fadeInRight">
                    <!--<h3 class="column-title">Our Company</h3>-->
                    <p><span style='text-decoration:underline'><a href="https://huggingface.co/uf-aice-lab/math-roberta" style='color:#2596be' target="_blank">MathRoBERTa cyberinfrastructure</a></span>: a large language model, which has been trained with 8 Nvidia GPUs and over 3,000,000 math discussion posts by students and facilitators on Algebra Nation. MathRoBERTa has 24 layers, and 355 million parameters and its published model weights take up to 1.5 gigabytes of disk space. Researchers can easily download and utilize this model to conduct a series of natural language processing tasks (e.g., text classification, semantic search, Q&A) in similar math learning environments. </p>
                </div>
            </div>
        </div>

        <br>
        <hr>
        <div class="container">
            <div class="row">
                <!-- img-responsive -->
                <div class="col-md-4 wow fadeInLeft">
                    <!-- img-responsive -->
                  <a href='https://huggingface.co/uf-aice-lab/git_20' style='color:#2596be' target="_blank"><img class="img-square" src="images/git_20.png" style="text-align:center" alt="">
                  <h3>Git_20 Model</h3></a>
                </div>

                <div class="col-md-8 wow fadeInRight">
                    <!--<h3 class="column-title">Our Company</h3>-->
                    <p style="margin-top: 5%;"><span style='text-decoration:underline'><a href='https://huggingface.co/uf-aice-lab/git_20' style='color:#2596be' target="_blank">Git_20 Model</a></span>: is a fine-tuned multimodal visual language model from Microsoft GIT using 1 Nvidia A100-80G GPU. We extracted 100,000 student assignments containing teacher feedback from 3 million student assignments as training data. The training data is divided into the image part of student assignments and the text part of teacher feedback. git_20 consists of 18 layers and over 170 million parameters, consuming up to 0.7 gigabytes of disk space. The project aims to use multi-modal and multi-task deep learning models to create a machine learning pipeline that provides automatic diagnostic feedback for students' mathematical reasoning. Researchers can experiment with and finetune the model to help construct multimodel that can effectively provide automatic diagnostic feedback for students' mathematical reasoning.  </p>

                </div>
            </div>
        </div>

        <br>
        <hr>
        <div class="container">
            <div class="row">
                <!-- img-responsive -->
                <div class="col-md-4 wow fadeInLeft">
                    <!-- img-responsive -->
                  <a href='https://huggingface.co/uf-aice-lab/BLIP-Math' style='color:#2596be' target="_blank"><img class="img-square" src="images/BLIP-Math.png" style="text-align:center" alt="">
                  <h3>BLIP-Math</h3></a>
                </div>

                <div class="col-md-8 wow fadeInRight">
                    <!--<h3 class="column-title">Our Company</h3>-->
                    <p style="margin-top: 5%;"><span style='text-decoration:underline'><a href='https://huggingface.co/uf-aice-lab/BLIP-Math' style='color:#2596be' target="_blank">BLIP-Math</a></span>: is a multimodal visual language model and has been fine-tuned on a comprehensive mathematical multi-modal dataset and incorporates two distinct output heads: text generation and scoring. We have made available the weight file specifically for the text generation component.  </p>

                </div>
            </div>
        </div>

        <br>
        <hr>
        <div class="container">

             <div class="row">
                <!-- img-responsive -->
                <div class="col-md-4 wow fadeInLeft">
                    <!-- img-responsive -->
                <a href='https://huggingface.co/uf-aice-lab/SafeMathBot' style='color:#2596be' target="_blank">
                  <img class="img-square" src="images/GPT2.png" alt="Ray">
                  <h3>SafeMathBot</h3>
                  </a>
                </div>

                <div class="col-md-8 wow fadeInRight">
                    <!--<h3 class="column-title">Our Company</h3>-->
                    <p><span style='text-decoration:underline'><a href="https://huggingface.co/uf-aice-lab/SafeMathBot" style='color:#2596be' target="_blank">SafeMathBot cyberinfrastructure</a></span>: build a large language model using state-of-the-art language GPT-2-xlarge which has been trained with 8 Nvidia GPUs and enhanced with conversation safety policies (e.g., threat, profanity, identity attack) using 3,000,000 math discussion posts by students and facilitators on Algebra Nation. SafeMathBot consists of 48 layers and over 1.5 billion parameters, consuming up to 6 gigabytes of disk space. Researchers can experiment with and finetune the model to help construct math conversational AI that can effectively avoid unsafe response generation. </p>
                </div>
            </div>
        </div>
        <br>
        <hr>
        <div class="container">
            <div class="row">
                <!-- img-responsive -->
                <div class="col-md-4 wow fadeInLeft">
                    <!-- img-responsive -->
                  <a href='https://github.com/uf-aice-lab/SPAC3' style='color:#2596be' target="_blank"><img class="img-square" src="images/SPAC3.png" style="text-align:center" alt="">
                  <h3>SPAC3</h3></a>
                </div>

                <div class="col-md-8 wow fadeInRight">
                    <!--<h3 class="column-title">Our Company</h3>-->
                    <p style="margin-top: 5%;"><span style='text-decoration:underline'><a href='https://github.com/uf-aice-lab/SPAC3' style='color:#2596be' target="_blank">SPAC3</a></span>: takes an innovative approach to address these gaps and provide evidence-based insights. It aims to develop visual programming functions suitable for upper elementary students, helping them learn spatial programming effectively. By doing so, it will contribute to our understanding of how this tool impacts students' spatial reasoning, computational thinking, and their interest in computationally-intensive careers.  </p>

                </div>
            </div>
        </div>
    </section><!--/#about-->


    <footer id="footer">
        <div class="container">
            <div class="row">
                <div class="col-sm-6">
                    &copy; 2022  <a href="index.html" title="ACE LAB">ACE LAB</a>
                </div>
                <div class="col-sm-6">
                    <!--customize icons-->
                </div>
            </div>
        </div>
    </footer><!--/#footer-->

    <script src="js/jquery.js"></script>
    <script src="js/bootstrap.min.js"></script> 
    <script src="js/mousescroll.js"></script>
    <script src="js/smoothscroll.js"></script>
    <script src="js/jquery.prettyPhoto.js"></script>
    <script src="js/jquery.isotope.min.js"></script>
    <script src="js/jquery.inview.min.js"></script>
    <script src="js/wow.min.js"></script>
    <script src="js/custom-scripts.js"></script>
</body>
</html>
